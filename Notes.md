# ecoinfoFAIR2020

## C'est qui ?

### Amélie Fiocca, IE INRAE, URFM, Avignon
- Mon travail : Mise en place des référentiels et d’un standard de métadonnées (projet IN-SYLVA), identification et intégration des éléments de provenance dans les systèmes d'information et les pipelines sémantiques développés (projet ENVRI-FAIR).
- Mon background : Développement informatique, écologie forestière, dendrochronologie

### Lorraine Coché, IE IUEM LETG
- Mon travail : suite de mon stage de M2 : "Inventaire et structuration des données d’observation des mammifères marins aux abords de la Guadeloupe". Développement d’une base de données cohérente et homogène face à l’hétérogénéité des sources de données d’observation dans l’objectif de comparer la répartition des cétacés et celle du trafic maritime dans l’espace maritime guadeloupéen
- Mon background : Biologie générale, Ecosystèmes marins tropicaux 

### Jean-Luc Jung, MCF UBO MNHN, 
- Mon travail : Etude de la diversité génétique et taxonomique de la mégafaune marine 
- Mon background : génétique et taxonomie moléculaires, travail de terrain (prélèvements - observations)
### Anthony Bretaudeau, Plateforme GenOuest Rennes, BIPAA, INRAE
- Mon travail : Je travaille sur les plateformes GenOuest (bioinformatique) et BIPAA (génomique des insectes). Développement d'applications web, un peu d'administration système (cluster GenOuest). Pas mal impliqué dans la communauté Galaxy: administrateur de galaxy.genouest.org, contributeur de usegalaxy.fr.
- Mon background : Développement, génomique des insectes
### Claudia Lavalley, CNRS, UMR TETIS - Maison de la Télédétection - Montpellier
- Mon travail: Accompagner les membres de l'unité vers la FAIRisation des données (donnes spatialisées en particulier), piloter la mise en place d'une Infrastructure de Données Géographiques (Geonetwork + Geoserver) pour l'UMR
- Mon background: physicienne (astronomie), double compétence en informatique, développement collaboratif pour expériences d'astroparticules, information spatiale/géomatique/télédétection pour l'aménagement des territoires
### Coline Royaux, IE CNRS, développement d'outils Galaxy au PNDB, UMS BBEES, station marine de Concarneau
- Mon travail : Adapter des scripts d'analyses de données de biodiversité existants à la plateforme Galaxy pour les rendre utilisables facilement sur un maximum de jeux de données
- Mon background : Ecologie générale et ingénierie écologique
### Elie Arnaud, IE MNHN, développement R / R Shiny et gestion de données/métadonnées au PNDB, UMS PatriNat, station marine de Concarneau
- Mon travail : développer des applications de saisie de métadonnées en apportant un soin particulier à l'automatisation des tâches de saisie (inférence à partir de la donnée), travailler à la communication de métadonnées inter-standards, R Shiny & Unix forever !
- Mon background : biologie généraliste, techniques en bio-info, spécialité en R 
### Emilie Lerigoleur, IE CNRS-INEE, UMR Geode (géographie de l'environnement), Toulouse
- Mon travail : géomaticienne à fond "partage et ouverture des données" ! impliquée dans projet ANR "science ouverte" pour la mise en place d'une e-infrastructure de données des observatoires hommes-milieux dans le cadre du LabEx DRIIHM, impliquée aussi dans la zone atelier Pyrénées-Garonne
- Mon background : écologue de formation orientée conservation des ressources génétiques végétales, puis reconversion avec master en géomatique 10 ans après !
### Julien Sananikone, MNHN, PNDB UMS PatriNat, Paris
- Mon travail : Faire ce que les autres ne veulent pas faire ... ;) 
- Mon background : Agronome, Gestion de Projets Informatiques, Développement informatique
### Guillaume Body, Ingénieur expert OFB, chargé de mission "Surveillance des vertébrés terrestes", OFB, Pérols
- Mon travail : Me poser tout le temps des questions liés à la surveillance de la biodiversité, et trouver les bonnes personnes pour m'apporter les réponses ( #Morgane #Sarah #Yvan #Elie et bientôt vous !)
- Mon background : Ecologie comportementale, ongulistes
### Nicolas Casajus, Data scientist, FRB-CESAB, Montpellier
- Mon travail : support stat pour les groupes de recherche Cesab, développement de packages R, mise en place de formations (reproductibilité, modélisation théorique), implication dans le rapport IPBES, etc.
- Mon background : biodiversité & changement climatique, analyses spatiales, etc.
### Philippe Clastre, IE CelluleBDSIG, URFM, INRAE
- Mon travail : Gérer les bases de données du labo. Faire en sorte que les données insérées soient propres et documentées. Développer des interfaces pour masquer les aspects SQL. Gérer les données spatiales. Animation collectif géomatique centre INRAE PACA et maintien en conditions opérationnelles des services. Animation collectif PGD dans le cadre de la cellule qualité centre. 
- Mon background : Développement, Bases de données, Docker, administration système, un peu de R et de shiny, gitlab sur forgeMIA 
### Raphaëlle Sauzède, IR CNRS-INSU, Data manager Biogeochemical-Argo (BGC-Argo), FR 3761, Villeranche-Sur-Mer
- Mon travail : Développer des outils adaptés afin d'établir un contrôle qualité en temps différé des données provenant des plateformes autonomes BGC-Argo (flotteurs profileurs)
- Mon background : bio-informatique (de formation), océanographie biogéochimique, analyse de données et machine learning
### Sabrina Le Cam PostDoc CNRS, La Rochelle
- Mon travail: Analyser des données *omiques en écologie moléculaire et organiser un espace/outil de travail collaboratif en bio-informatique au sein de l'équipe
- Mon backgroung: Biologie marine, Biologie évolutive, Ecologie
### Sarah Valentin, Chargée de projet Enetwild, OFB, Pérols
- Mon travail : Standardisation de données de présence et d’abondance de faune sauvage à l’échelle européenne (focus sur le sanglier), dans le format Darwin Core
- Mon background : Epidemiosurveillance, santé animale, informatique
### Morgane Maillard, Ingénieure - Tableau de bord pour le suivi de la biodiversité terrestre, UMS PatriNat, OFB, Pérols
- Mon travail: Développement d'une application shiny pour collecter les métadonnées des programmes de suivi de la biodiversité terrestre.
- Mon background: Ecologie forestière, écologie du sol, bio-informatique et modélisation.
### Yvan Le Bras, IR MNHN, Chef de projet "Pôle national de données de Biodiversité" (PNDB de son petit nom), UMS PatriNat, station marine de Concarneau
- Mon travail : Me poser tout le temps des questions liées à la gestion et l'analyse de données de biodiversité ;)
- Mon background : Ecologie marine, Analyse de données *omiques, Bioinformatique
### Simon Bénateau, IR MNHN, Coordinateur adjoint Vigie-Nature École et chef de projet Galaxy-Bricks
- Mon travail : Proposer des protocoles de sciences participatives à des élèves et les initier à la démarche scientifique/analyse de données
- Mon background : Agronomie, Ecologie
### Sébastien Rochette, formateur et développeur R, ThinkR
- Mon travail : Former à R, de l'initiation au développement Shiny, en passant par le développement de package R. Accompagner les organismes, instituts et entreprises dans leurs pratiques de développement avec R. Développer des applications R statiques ou interactives pour répondre aux besoins en analyses de données.
- Mon background : Ingénieur halieute, Docteur en biologie marine. Des années à développer, modéliser, cartographier avec R...

### Alain Danet, Post-doc MNHN, Paris
- Mon travail: je cherche à comprendre les liens entre les interactions entre espèces, leur coexistence et le fonctionnement des écosystèmes. Comme je déteste devoir faire plus de deux fois la même chose, je code beaucoup!
- Mon background: écologie et évolution

### Denis Lafage, Post-doc ECOBIO, Rennes 1
- Mon travail: Etudier les communautés et les réseaux trophiques des interfaces eau/terre. Dépanner les collègues qui galèrent avec R, le Bayesien et les SIG...
- Mon background: 10 ans de gestion de BDD et SIG en asso de protection de la nature avant la recherche en Ecolgie des communautés.

### Charlotte Roemer, Post-doc MNHN, Paris
- Mon travail: Animation de Vigie-Chiro, programme de sciences participatives pour le suivi des populations de chauves-souris. Développement d'un classificateur de sons de chauves-souris.
- Mon background: Ecologie, Bioacoustique, manipulation d'enregistreurs d'ultrasons et analyses de grosses bases de données.

### Jérôme Micucci, MNHN, Paris
- Mon travail : développement du site internet Vigien-Nature École.
- Mon background : développement web, touche à tout.

### Mathias Rouan, IR CNRS, LETG, Brest
- Mon travail : SIG, Infrastructure de données spatiales, Webservices, modélisation multi-agents (SMA)
- Mon background : Biologie Marine, géomatique, informatique

### Jean Cohen, Stagiaire MNHN, Paris
- Mon travail : développement d'un algorithme de reconnaissance automatique d'insectes à partir de photos pour la plateforme de sciences participatives SPIPOLL (deep-learning)
- Mon background : cursus ingénieur généraliste - traitement d'images - reconstruction tomographique

### Iwan Le Berre, MCF UBO, Brest
Mon travail : Etude de l'anthropisation des systèmes littoraux, coordinateur du projet TRAFIC, mis en oeuvre dans le cadre de l'OHM littoral Caraïbe sur la vulnérabilité des régions portuaires de l'espace Caraïbe au trafic maritime (qualité de l'air', dérangement des mammifères marins, inégalités environnementales).
Mon background : géographie humaine des littoraux, géomatique

### Françoise Le Moal, IE Ecobio, Rennes
Mon travail: Promouvoir le FAIR data au sein d'Ecobio, les métadonnées via l'IDG 'OSURIS' basée sur GeoNetwork/GeoServer, support bases de données relationnelles, veille FAIR Data

### Arnaud Jean-Charles, Chargé de projet Web-Data, Aix en Provence
- Mon travail : aide à la gestion des données de la recherche du LabEx DRIIHM : catalogage, photothèque, sites web...
- Mon background : développeur web-SIG

## C'est où ?

### Concarneau

Pour le site de Concarneau, rendez-vous à la Station de Biologie Marine / Marinarium, à gauche derrière la boutique (panneaux "salle de conférence").

### Paris

Pour le site de Paris, rendez-vous dans le jardin des plantes en salle Claude Hélène (bâtiment de la Baleine) Entrée côté Jussieu. Contacter Simon Bénateau en cas de besoin : simon.benateau@mnhn.fr ou 0644868139.

### Montpellier

Pour le site de Montpellier, rendez-vous au CESAB situé au 5 rue de l'école de Médecine (bâtiment IBB), rentrez dans l'enceinte, contournez le bâtiment par la droite et prenez les escaliers jusqu'à ne plus pouvoir monter. Contactez Nicolas Casajus au besoin : nicolas.casajus@fondationbiodiversite.fr ou 0786330337.

## Outils de communication pour cet événement
Serveur **BigBlueButton** accessible à cet URL : https://webconf.math.cnrs.fr/b/yva-rtm-4mv.

En solution de dépannage, notamment en cas de problèmes, je propose d'utiliser **jitsi** via cet URL : https://meet.jit.si/ecoinfoFAIR2020.

Partage de fichiers : https://data-access.cesgo.org/index.php/s/1MKUDQZzVdTkCPx

## Programme prévisionnel

L'idée est de faire une première ~demi journée de présentation/formation introductive puis un grand temps d'échange (~2 jours) de travail en petits groupes

### Matin 19 : Intro (11h- 12h45)

- Introduction aux journées en présentant la vision FAIR du PNDB

### Après-midi 19 : plusieurs intervenants (14h-17h35) :
*Par rapport au programme initiale, compte tenu de l'aspect distanciel ne facilitant pas le fait d'échanger autour des présentations faiclement et cela durant plusieurs heures, nous avons pris la décision de réduire les présentations en temps et nombre. Cela permettra de prendre plus de temps à la mise en place des groupes de travail dès la fin de la première jourée. Pour autant, ne pas hésiter si vous souhaitez aborder certains points durant les 2 jours!*
- Aspect outils "génériques" de développement en écologie, orienté R
   - Bonnes pratiques de travail avec R / science reproductible / workflow / package via R, RStudio *by Terrific* ***Sébastien Rochette, ThinkR***
   - Formation rapide développement d'une application Shiny *by amazing **Elie Arnaud, PNDB***
- Aspect Métadonnées
   - Formation rapide introductive à l'EML, ***Julien Sananikone, Elie Arnaud, Yvan Le Bras, PNDB***
- Aspect Analyse de données
   - Formation rapide introductive à dev Galaxy *by wonder **Coline Royaux, PNDB***
### Formations introductives supplémentaires si besoin / demande
- Formation rapide introductive à GIT et github 
- Formation rapide introductive à Docker avec application en SIG
- Formation dev Galaxy et Conda en détail

### Après-midi 19 : mise en place des groupes de travail (16h15-18h) :
- Présentation des sujets mentionnés
- Echanges autour de ces derniers et de la mise en place des gruopes de travail
### Matin 20 (9h) -> Après-midi 21 (16h) : Travail en petits groupes / Hackathon / Collaboration Fest
- Sujets potentiels
   - développements "métadonnées" liés aux standards utilisés en écologie (Darwin-core / EML / ISO19115 / ISO19110...) et/ou aux catalogues de données/métadonnées (GeoNetwork/Metacat/Dataverse/Zenodo...)
       - ***Workflow BDD postgis mammifères marins (modélisée avec standards DarwinCore et EML) -> liste requêtes d’intérêt -> publication dans Metacat + geonetwork + GBIF ? (Emilie)***
           - mettre au point un workflow de création / structuration de bdd et publication dans metacat voire GBIF
           - standardiser les descripteurs (attributs des données) + métadonnées (qui, quoi, ou et comment)
                - mapper les attributs avec DarwinCore 
        - ***Lien Metacat - geoserver en s’appuyant sur SOLR : publier des flux WMS/WFS des (méta)données mammifères marins issues de Metacat (Arnaud)***
   - développement de scripts R en mode function / package
   - développement d'applications R Shiny
       - ***Tableau de bord de la surveillance de la biodiversité terrestre (Guillaume, Morgane, (Sarah?))***
       - ***Visualisation des résultats d'une participation Vigie-Chiro (Charlotte, Yves?)***
       - ***Dockerisation (via shinyproxy?) : https://shinyproxy.io/getting-started/ & https://www.rdocumentation.org/packages/golem/versions/0.2.1/topics/add_dockerfile***
   - containerisation d'applications R Shiny pour intégration dans Galaxy
   - développement d'outils Galaxy à partir de scripts R
   - développement de matériels de formation 'e-learning" via l'infrastructure du Galaxy Training Network

## Prise de Notes
### Tour de table
- Paris
Alain Danet
Jerome
Jean stage CESCO développement algo IA reconnaissance insectes
Simon Benateau MNHN Vigie-Nature Ecole
- Montpellier
    - Morgane PAtriNAt OFB-MNHN-CNRS Shiny métadonnées sur dispositifs suivi de biodiversité terrestre
    - Sarah Valentin OFB projet EUropéen EnetWild pour standardiser données présences absences biodiv terrestre focus sanglier
    - Nicolas Casajus CESAB FRB
    - Guillaume Body OFB Surveillance des vertébrés terrestres
- Amélie Fiocca ENVRI-FAIR (Aspects Provenance) / IN-SYLVA (standard)
- Charlotte Vigie-Chiro accoustique et chauve souris / intérêt sur Shiny
- Claudia UMR TETIS Montpellier responsable infra de données géographique pour l'unité
  - membres unité plutôt utilisateur de données Biodiversité que producteur !
- Concarneau
Coline PNDB Galaxy-E et écharpe jaune
Elie PNDB ingé données / métadonnées et développeur MetaShARK
- Denis ecobio genet des pop / trophique et gestion données SIG
- Emilie géomaticienne FAIRisation des données / projet ANR SO-DRIIMH / Observatoires Hommes Milieux
- Françoise ecobio gestion de données - métadonnées / FAIRisation / OSU Rennes
- Gabrielle CESCO Vigie-Nature plantes et papillons
- Jean-Luc macrofaune marine UBO Brest / données ADN / projet OHM littoral Carïbes / Sciences participatives
- Lorraine UBO Brest / projet trafic / structuration bdd observation mammifères marins / sciences participatives / données très hétérogènes / production des métadonnées et AIRisation des données
- Iwan UBO Brest / projet trafic / bdd observation mammifères marins and co / comment connecter données AIS avec données cataloguage
- Loubna CESCO Vigie-NAture / indice de biodiv - restitution web / Traitement SIG
- Mathias UMR LETG géomatique / infrastructure de données géospatialisée - SIG / TEchno R et R Shiny l'intéresse, notamment pour valorisation des données
- Philippe URFM Avignon INRAE / arbres / gestion bdd infos sur arbres / développement Shiny pour présenter aux gens ne connaissant pas postgres - SQL les données / SIG GeoNetwork - Geoserveur pour porter à connaissance via projet ANAee France / avec aspects sémantiques - sémantisation / désémantisation pour publication dans entrepôt genre Dataverse
- Raphaelle Institut de la mer de Villefranche / réseau d'observatoire ARGO via flotteurs / données biogéo-chimiques / développement d'outils adaptés aux utilisateurs pour que les données soient la plus juste possible / R, Shiny, Python
- Sabrina Le Cam Post doc à L'université de La Rochelle. Je travaille en génomique des populations et transcriptomique sur un bivalve marin
- Sophie GBIF / données de biodiversité / standard d'échange de données/métadonnées
- Sébastien ThinkR / formation et prestation autour de R / scripts, packages, Shiny.
### Aspect outils "génériques" de développement en écologie, orienté R
#### Introduction aux journées en présentant la vision FAIR du PNDB
Présentation : Yvan Le Bras, Pôle national de données de Biodiversité, MNHN
- Contextes : (méta)données trop peu accessibles, 6ème extinbction massive de biodiversité, volumes de données/big data en forte progression vs limite des capacités de stockage, problème de communication entre (sous-)domaines scientifiques et avec les citoyens
- Accessibilité de la donnée en écologie : 1% de données sensibles (liées aux espèces menacées), pourquoi partager les données ? se battre contre les climato-sceptiques et accélérer la production de connaissances pour mieux protéger la biodiversité
- PNDB : 
    - sa place au sein du réseau d'infrastructures de recherche Terre-Environnement du MESRI. Objectif de construire un pôle de données pour diffuser les données des TGIR/IR nationales et faciliter le couplage avec des données autres dont celles de data-Terra --> le PNDB vise à ajouter une plus-value par rapport à l'existant !
    - 10 lignes de force : orientation FAIR, relier avec IR système Terre-Env, articuler avec SIB-SIMM, nouveaux services, qualité plutôt que quantité, flexibilité des services, description fine des données, portée internationale, articuler avec EOSC and co, quelques uses cases !
    - 3 volets : accès aux métadonnées / animation et accompagnement / accès aux outils de traitement/couplage/calcul
    - outils mis en oeuvre : https://www.pndb.fr, https://data.pndb.fr, https://metashark.test.pndb.fr, https://ecology.usegalaxy.eu
    - perspectives, quelques pointeurs : 
        - H2020 MOODA (massively only open data analysis) concept -> générateur d'outil d'annotations dans galaxy (intérêt en science participative notamment), 
        - concept de Galaxy-Bricks pour faire une interface dans une communauté dédiée
        - intégration de données au "jumeau numérique"


#### Formation rapide introductive à GIT et github -> A voir pour faire un point mardi ou mercredi si personnes intéressées
Présentation : Alain Danet, UMR CESCO, MNHN / Nicolas Casajus, CESAB, FRB
Personnes intéressées : ......... à compléter !


#### Bonnes pratiques de travail avec R / science reproductible / workflow / package via R, RStudio
Présentation : Sébastien Rochette, ThinkR / Statnmap

Pour info, matériel utilisé lors de la première édition ecoinfoFAIR par Sébatien : https://github.com/statnmap/course_material
https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/

https://github.com/statnmap/prez/blob/master/2020-10-ThinkR-development-workflow.pdf
- PROPRE = PROcessus de Publications REproductibles
- Tout se passe dans R, on évite les étapes non reproductibles (e : cartes dans QGIS, graphes dans calc) --> tout est code :)
- S'assurer que tout le monde puisse reproduire une analyse
- Nécessite stabilité des données brutes
- Approche DataOps (data = producteurs / obs = utilisateurs) et devOps (dev = développeurs R)
- DevOps en 6 étapes (avec itérations étapes 3 à 6):
    - infra : def des rôles, création gitlab pour gérer le projet, monitorer le projet avec Kanban, com asynchrone et/ou fils de discussion (chat, issues)
    - design UI : se poser les questions quel public cible ? quels sont les besoins ? etc. et propositions visuelles (format de rapport, application Shiny, etc.)
    - Protototype : dans package R structuré avec documentation structurée et site web à l'aide du package pkgdown pour le partage, documentation du process aussi à la racine du package
    - Build : combiner apparence avec le coeur du devt, en sortie : rapport et/ou application Shiny
    - Strengthen : 
        - Mise en place de tests unitaires via test_that avec couverture en test (100% des fonctions testées via tests unitaires)
        - Intégration continue / test du package dans un container Docker
    - Deploy : envoi en prod (rapport, Shiny apps) avec preuves de qualité avec packages testdown et gitdown
    - Repeat 3:6

- Mention des packages carto nécessitant d'avoir des packages systèmes genre GDAL and co -> utilisation de Docker pour gérer ce pb, notamment les Docker "Rocker" https://hub.docker.com/r/rocker/verse

- Shiny est t-elle toujours la réponse à une envie de développer une interface aux utilisateurs, genre un rapport md / html peut suffire

#### Questions pour Sébastien
- comment pouvoir toucher "tout le monde" par exemple le citoyen sans compétence en programmation ?
- stabilité des données brutes = format des données et/ou "juste" noms de certaines variables / Que bdd ou que fichiers plats ?
- Intégration Continue direct via gitlab/github ?
- Jérôme : Quand tu dockerises ton appli shiny, tu encapsules le serveur shiny avec ? --> soit avec Rstudio connect, sinon avec Shiny proxy qui lance docker
- Paris : je me demandais à combien vous collaborez en général sur ces projets? Et si tu penses que ton approche est facilement adaptable quand seul ou en très petit nombre ? --> 25 pers pour le projet de la DREAL + supervision (définir correctement les rôles de chacun + com = la clé du succès !)
- Philippe : shinyproxy: permet de contourner la limitation d'un seul user sur un shiny server ?
- Info Sébastien concernant le WSL2 https://korben.info/installer-wsl2-windows-linux.html et pour docker sous windows :https://korben.info/installer-docker-windows-home.html
- Philippe : Question pour une application shiny connectée à une bdd postgres, avec des requêtes lentes. Quelle stratégie pour récupérer les données ? Et comment Partager les données entre différents utilisateurs connectés simultanément (variables globales ?) --> voir pour faire en asynchrone avec packages {promises} (https://rstudio.github.io/promises/) et {future} (https://github.com/HenrikBengtsson/future)...
- Iwan : Outre les nombreuses méthodologiques et techniques, peut-on proposer des idées d'applications ? Par exemple pour la production de synthèses cartographiques et graphiques à partir de la BD Kakila des observations de mammifères marins en Guadeloupe ? Oui, il faut l'avouer, c'est une question très intéressée... --> s'assurer d'abord si Shiny est utile et le bon outil pour ça ! ça dépend aussi de la fréquence de mise à jour des données. --> La fréquence de mise à jour des données peut se gérer avec le CRON système.

#### Formation rapide développement d'une application Shiny
Présentation : Elie Arnaud, Pôle national de données de Biodiversité, MNHN
https://github.com/pole-national-donnees-biodiversite/metadata-training/tree/master/Presentations
tuto_shiny_elie.pdf

- package R de type interface R-HTML
- **le U de Shiny** : UI = interface utilisateur + partie serveur
    - UI input : objet ui stocke l'entrée
    - Server 
        - input : objet server
        - reactive : pour traiter les variables d'entrée
        - output : liste avec différents nommés (ici de type texte) et renvoi de my.input()
    - UI output : renvoi la sortie
- **Modules** : on complexifie la tâche avec des modules et sous-modules (pour découper un script en plusieurs scripts, pour avoir appli plus lisible) : modules Main.R, Feature_1.R et Feature_2.R. Ces modules peuvent intervenir à différents moments du process. On organise les modules comme des minis applications qui sont appelés grâce à leurs identifiants.
- **App's runtime** : comment se déroule l'exécution d'une application ? grâce au package reactlog on peut voir comment se comporte l'appli sous la forme d'une frise chronologique.
- **Dictionnaire des outils utiles** : formats pré-fabriqués, inclusion de styles (CSS) pour améliorer l'ergonomie de l'appli. cf. packages shinydashboard et shinydashboardPlus (intégrant Bootstrap), shinymaterial (plutôt pour les applis mobiles), shiny.grid (coup de coeur !) plus complexe à prendre en main mais contrôle très fin des éléments de l'appli.
- **Famille des éléments au niveau UI et server** : cf tableaux dans pdf !
- **Liste des packages utiles** : cf liste dans pdf !
- Exemples : https://metashark.test.pndb.fr/ et https://sparktuga.shinyapps.io/ShinyDecisions/

Bonnes pratiques /recommandations de Sébastien : 
On écrit toujours tout en minuscule, avec des mots séparés par des underscores, comme ça, on réduit les soucis... (namespaces, nom de fonctions, paramètres)
Pour les interfaces différentes de ShinyDashboard, David Granjon en a proposé d'autres ici : https://rinterface.com/
Faire une application Shiny n'implique pas de savoir faire du Shiny dans un premier temps. Le Rmd-first est la clé.
Rmd first, ça veut dire qu'on commence le développement dans un fichier Rmarkdown (texte + script R classique).
Ce qu'on a fait l'an dernier : https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/
Les slids d'une prez ici: https://github.com/statnmap/prez/blob/master/2019-07_useR_Toulouse.pdf
La version longue dans un article de blog, c'est ici: https://rtask.thinkr.fr/fr/quand-le-developpement-commence-par-la-documentation/
Si on fait une application Shiny, je vous recommande de le faire dans le cadre d'un package R, donc on peut aussi faire le package dans ce cadre
Docker du Shiny: golem::add_dockerfile()

Autres ressources:

- le livre de Shiny: https://mastering-shiny.org/scaling-modules.html#case-studies
- plus poussé, le site W3schools, LA référence des pages HTML et du CSS: https://www.w3schools.com/ (souvent atteint lors de recherches sur des composants de l'UI)

#### Questions pour Elie
- Peut on avoir un exemple pour s'exercer en fin de journée de notre côté pour nous familiariser avec le fonctionnement, stp?

```
# App.R
ui ← fluidPage(
textInput(“text”, “Type here”),
textOutput(“written”)
)

server ← function(input, output, session){
my.input ← reactive({input$text})
output$written ← renderText({my.input()})
}

shinyApp(ui, server)
```
- est-ce qu'on pourrait avoir un aperçu (démo ?) des 3 exemples cités au début ?? --> Exemples : https://metashark.test.pndb.fr/ et https://sparktuga.shinyapps.io/ShinyDecisions/
- Et pas de {golem} ? :-)
- Vous avez fait le choix de développer Metashark en Rshiny: pourquoi pas PHP ou autre langage pur web ? --> EMLAL déjà développé dans R et choix stratégique de R pour permettre à des contributeurs futurs (chercheurs, IT) dans leur propre langage de prédilection :)

#### Formation rapide introductive à Docker avec application en SIG -> A voir pour faire un point mardi ou mercredi si personnes intéressées

Présentation : Julien Ancelin, LIENSs - Unité Expérimentale St Laurent de la Pré, INRAE

Ressources de la dernière édition (et première) d'ecoinfoFAIR : 

Pour un tuto que vous pouvez effectuer :
https://labs.play-with-docker.com/ et 
 /!\ Pour le tuto Docker: pour jouer avec Docker, créez un compte sur https://hub.docker.com//!\
 
 Slides : https://jancelin.github.io/workshop_docker_GIS/#1
 
premier test, lancer cette commande :
    `docker run --rm -d -p 8787:8787 -e PASSWORD=12345678 rocker/rstudio:3`

 et cerise sur la gâteau : https://hub.docker.com/r/jancelin/docker-lizmap pour un docker compose et application WABSIG !
    
```
wget https://raw.githubusercontent.com/jancelin/docker-lizmap/3.2.2/docker-compose.yml

docker-compose up
```

   Problèmatiques sous windows, mais aide via Kitematic pour interface de gestion d'images et containers Docker.



### Aspect données et Métadonnées


#### Formation rapide introductive à l'EML
Présentation : Yvan Le Bras, Pôle national de données de Biodiversité, MNHN
- Constat : perte d'informations avec le temps -> important de documenter les données (= métadonnées)
- pourquoi des métadonnées ? pour aller de la donnée à la connaissance en passant par l'information, il faut des métadonnées
- quel niveau de description ? décrire les variables primaires et pouvoir gérer la provenance (traçabilité des protocoles, outils et workflow d'analyses) pour permettre la reproductibilité
- renseigner les variables primaires = coeur de l'EML (= eml_attributes)
- par rapport aux standards géospatiaux ISO 19115/19139 : EML plus utilisés en Australie et USA (à travers les LTER notamment) alors qu'en Europe on utilise plutôt ISO19115. ISO19110 sous-utilisé alors qu'utile pour décrire les variables.
- EML langage modulaire flexible, traçage de provenance possible. L'EML semantics permet d'utiliser des ressources terminologiques (thesaurus/ontologies) pour faire le lien entre les fichiers bruts avec les variables standardisées (ex darwin core).
- aller vers le concept de "Research objects" qui intègre tout !

> "Si Internet est une réussite, c'est parce que tout le monde, dans le monder entier, s'est mis d'accord pour utiliser le même processus HTTP"


#### Questions pour Yvan
- Philippe : Combien de champs pour une fiche de métadonnées EML standard ? --> 220 pour MetaShARK :)
- Philippe : Polémiquons: On a déjà du mal à faire compléter une fiche ISO19115
- Simon : Je suis intéressé par l'idée de faire des datapaper pour les données vigie-nature ! --> avec MetaShARK draft de data paper généré automatiquement (avec emldown). Pour GBIF le fichier EML est une bonne base de draft de data paper également (Arpha writing tool (éditions Pensoft)).
- Claudia : EML est très lié à la thématique écologie. Si l'on devait l'étendre à d'autres disciplines, serait-ce faisable? Comment se compare par exemple la partie attributs d'EML avec le modèle O&M de l'OGC? --> intégrer disciplines proches. Rem : Data Terra a opté pour un modèle pivot O&M et ISO19115 (avec mapping EML prévu pour lien avec PNDB)
- Jérôme : Très concrétement, le langage de description reprend la syntaxe de l'XML ? --> oui
- Claudia : Et par rapport à la provenance? --> oui ils utilisent prov_o
- Julien : metasnake fait du datapaper custom (pas lié à emlDown)

### Aspect Analyse de données

#### Formation rapide introductive à dev Galaxy
Présentation : Coline Royaux, PNDB /
Anthony Bretaudeau, Plateforme GenOuest Rennes, BIPAA, INRAE

Si quelqu'un veut voir à quoi ressemble galaxy bricks :
https://bricks.vigienature-ecole.fr/
galaxy écologie :
https://ecology.usegalaxy.eu/

- Pourquoi utiliser galaxy : reproductibilité, automatisation et rigueur
- Exemple de **généralisation** :
    - étape 1 : télécharger des données
    - 2 : sous R (en local) écrire script : exemple définir dossier de travail, import des tables de données, stats de base (on veut l'appliquer à plein de fichiers automatiquement)
    - 3 : travail sur invite de commande (config idéale Linux ubuntu) et éditeur de texte
        - cf 5 lignes de commande à exécuter
        - éditer le fichier texte avec balise <tool>...</tool> avec :
            - une description
            - les dépendances (packages R ici)
            - construire les sorties des input et output
            - écrire un help
        - écrire le script R en chargeant les arguments ici un seul avec import, analyse et rendu dans summary.txt
    - 4 : lancer en ligne de commande `planemo l Toolname.xml` pour tests unitaires
    - 5 : lancer `planemo s Toolname.xml` pour déployer l'instance galaxy locale qui s'ouvre sur le navigateur. Il ne reste plus qu'à charger toutes les données, puis sélectionner ceux d'intérêt et clic sur start et hop ! on obtient un summary.txt par fichier de données.
    - 6 : mettre les fichiers de sortie dans le rep test-data
    - 7 : on peut relancer `planemo l Toolname.xml` pour test unitaire : les 2 tests sont ok ! -> l'outil est prêt pour utilisation !
    - Exemple dév par Coline : 5000 lignes pour 5 outils
- Pour un scrit plus complet il vaut mieux faire de l'**atomisation** : cf. doc galaxy

#### Questions pour Coline
- Sébastien : Galaxy bricks, ça repose sur une app Shiny ? --> non django - galaxy et des scripts R
- Philippe : enjeu institutionnel pour le PNDB d'exposer un serveur galaxy ? serveur galaxy europe pour la communauté en écologie = une chance !
- Guillaume : Penses-tu l'adapter au niveau "écologue pas bioinformaticien" ?? ici c'est montré en tant que contributeur. C'est au moins pour ceux qui développent bien et veulent partager leurs scripts atomisés. Il y a les packages R en alternative.
- Claudia : partage de workflows ? --> oui on peut partager ça  https://ecology.usegalaxy.eu/u/ylebras/h/coral-reef-survey et le workflow correspondant https://ecology.usegalaxy.eu/u/ylebras/w/workflow-constructed-from-history-population-and-community-metrics-calculation-from-biodiversity-data-1
- Dans galaxy on peut déployer un jupyter notebook







### soir 19 : préparation Hackathons (17h36-18h30) :

#### Développements "métadonnées" liés aux standards utilisés en écologie (Darwin-core / EML / ISO19115 / ISO19110...) et/ou aux catalogues de données/métadonnées (GeoNetwork/Metacat/Dataverse/Zenodo...)

##### Sous-sujet 1 : Workflow BDD postgis mammifères marins (modélisée avec standards DarwinCore et EML) -> liste requêtes d’intérêt -> publication dans Metacat + geonetwork + GBIF ? (Emilie)
- Emilie-Sarah-Guillaume-Claudia-Yvan-Amélie-Iwan-JeanLuc-Lorraine
    - mettre au point un workflow de création / structuration de bdd et publication dans metacat voir GBIF
    - modèle de données - standardiser les descripteurs (attributs des données) + métadonnées (qui, quoi, ou et comment)
        - mapper les attributs avec DarwinCore 
cf CR et synthèse dans Collaboration Fest / Groupe 1
##### Sous-sujet 2 : Lien Metacat - geoserver en s’appuyant sur SOLR : publier des flux WMS/WFS des (méta)données mammifères marins issues de Metacat (Arnaud)
- Arnaud-Julien

#### Création de FAIR Implementation Profile
- Yvan-Françoise-Amélie (IN-Sylva) - Philippe ? - 
    - dossier partagé ici https://data-access.cesgo.org/index.php/s/P79IqHpT8pfRdFv avec deux fichiers word avec les informations pratiques pour mener une interview pour remplir le questionnaire permettant de créer le fameux FAIR Implementation Profile, ou FIP ;) et un fichier .pdf qiu est le résultat du premier FIP que j'ai créé pour le GBIF. Bon, pas forcément parfait, mais je trouve intéressant de tenter de remplir ce genre de questionnaire par communauté et SI lié. Dans les fichiers word ils expliquent comment faire le travail en utilisant https://fip-wizard.ds-wizard.org/ après s'être créé un compte pour répondre au questionnaire, et même l'installation de l'outil nanobench pour créer ce qu'ils appellent des nanopublications, une nanopublication décrivant une nouvelle ressource pouvant être sélectionnée dans le questionnaire (pour les réponses au questionnaire pas dans la liste des propositions ni dans wikidata). Là c'est un peu technique, mais une façon de faire serait ""juste"" de prendre le document pdf en version word (je dois l'avoir qqpart) et le remplir pour chaque communauté / SI. (Françoise Le Moal ?)
- Yvan-Amélie-Philippe mapping métadonnées EML-In-Sylva

-> sujets provenance / ressources terminologiques peuvent être des sujets à traiter par la suite

#### Data Paper via EML
Simon-Yvan

Futur action data paper :

https://mi-gt-donnees.pages.math.unistra.fr/site/index.html



#### développement d'applications R Shiny
##### Aide sur application déjà créée
- Morgane-Charlotte-Elie
- 
- Morgane - Elie ***Tableau de bord de la Surveillance de la biodiversité terrestre (Morgane, Guillaume)***
    - mettre au point un workflow de création de descriptions des programmes de mesures de la biodiversité (i.e. métadonnées sans lien direct avec un jeu de données) en suivant l'exemple MetaShark du PNDB. Espaec partagé : https://data-access.cesgo.org/index.php/s/zkkiaSXB9tNspBU
        - Enregistrement et mise à jour des informations
        - Connection à des référentiels
        - login ?
- Charlotte Roemer - travailler sur les options d'affichage des fenêtres dans shiny : comment ajuster le contenu pour éviter de scroller, ou au contraire comment rajouter une possibilité de scroller quand elle n'y est pas (Charlotte Roemer / Yves Bas)
- Outre les nombreuses méthodologiques et techniques, peut-on proposer des idées d'applications ? Par exemple pour la production de synthèses cartographiques et graphiques à partir de la BD Kakila des observations de mammifères marins en Guadeloupe (Iwan) ?


- Raphaelle sur Shiny l'après midi

#### Création package

- Nicolas-Alain-Sébastien-Loubna-Denis-Charlotte-Simon-Sabrina-Loubna

#### Mapping IN-SYLVA, EML, ISO19115, MIAME
Vois spécification IN-SYLVA (csv et latex)

#### Dockerisation
- Jérôme
un Dockerfile pour construire un Docker customisé sous Ubuntu 18.04 avec R installé : https://hackmd.io/k4QstIAKRNaalE8NuLxHmA


#### Autres
- Amélie IN-Sylva (standard créé basé sur INSPIRE/ISO19115 et mapping EML) / ANAee / ENVRI-FAIR provenance -> métadonnées

- Sylvain

- Loubna / Vigie-Nature. PArtir des bdd de sciences participative MNHN / produire indices de biodiversité sur R via fonction automatisant le calcul puis genèse fichiers JSON puis un javascript et un html tape dans le JSON pour afficher sur page web.
    - indices numériques, pas trop de soucis car valeurs numériques (nombre d'enregistrerurs enregistrés.)
    - indices carto, plus compliqué (répartition et pouvoir mettre en lien avec corine land cover)
        - fichiers vecteurs utilisés mais elle a pas réussi a les traiter sans faire planter R car données trop volumineuses
            - Faire requête sur données au préalable via QGIS ou autre ? bof car reproductibilité difficile si pas tout dans R
            - shp et geopackage

- Simon :
    - Bricks - voir avec Julien pour les modifs prévues et peut-être un peu pour de la traduction / outils pour des observatoires précis.
    - shiny pour une application d'apprentissage à l'analyse des données (galaxy-paper) voir si quelqu'un a des idées pour une jolie interface / amélioration de l'appli shiny via potentiellement des tests ou passage en package
    - Vers un datapaper Vigie-Nature Ecole pourquoi pas avec EML par exemple... 

















### Hackathons
#### Développements "métadonnées" liés aux standards utilisés en écologie (Darwin-core / EML / ISO19115 / ISO19110...) et/ou aux catalogues de données/métadonnées (GeoNetwork/Metacat/Dataverse/Zenodo...)
##### Sous-sujet 1 : Workflow BDD postgis mammifères marins (modélisée avec standards DarwinCore et EML) -> liste requêtes d’intérêt -> publication dans Metacat + geonetwork + GBIF ? (Emilie)
- Emilie-Sarah-Guillaume-Claudia-Yvan-Amélie-Iwan-JeanLuc-Lorraine
    - mettre au point un workflow de création / structuration de bdd et publication dans metacat voir GBIF
    - modèle de données - standardiser les descripteurs (attributs des données) + métadonnées (qui, quoi, ou et comment)
        - mapper les attributs avec DarwinCore 
cf CR et synthèse dans Collaboration Fest / Groupe 1
##### Sous-sujet 2 : Lien Metacat - geoserver en s’appuyant sur SOLR : publier des flux WMS/WFS des (méta)données mammifères marins issues de Metacat (Arnaud)
- Arnaud-Julien
#### Création de FAIR Implementation Profile
dossier partagé ici https://data-access.cesgo.org/index.php/s/P79IqHpT8pfRdFv avec deux fichiers word avec les informations pratiques pour mener une interview pour remplir le questionnaire permettant de créer le fameux FAIR Implementation Profile, ou FIP ;) et un fichier .pdf qiu est le résultat du premier FIP que j'ai créé pour le GBIF. Bon, pas forcément parfait, mais je trouve intéressant de tenter de remplir ce genre de questionnaire par communauté et SI lié. Dans les fichiers word ils expliquent comment faire le travail en utilisant https://fip-wizard.ds-wizard.org/ après s'être créé un compte pour répondre au questionnaire, et même l'installation de l'outil nanobench pour créer ce qu'ils appellent des nanopublications, une nanopublication décrivant une nouvelle ressource pouvant être sélectionnée dans le questionnaire (pour les réponses au questionnaire pas dans la liste des propositions ni dans wikidata). Là c'est un peu technique, mais une façon de faire serait ""juste"" de prendre le document pdf en version word (je dois l'avoir qqpart) et le remplir pour chaque communauté / SI. (Françoise Le Moal ?)
#### développement d'applications R Shiny
- ***Tableau de bord de la Surveillance de la biodiversité terrestre (Morgane, Guillaume)***
    - mettre au point un workflow de création de descriptions des programmes de mesures de la biodiversité (i.e. métadonnées sans lien direct avec un jeu de données) en suivant l'exemple MetaShark du PNDB. 
        - Enregistrement et mise à jour des informations
        - Connection à des référentiels
        - login ?
- travailler sur les options d'affichage des fenêtres dans shiny : comment ajuster le contenu pour éviter de scroller, ou au contraire comment rajouter une possibilité de scroller quand elle n'y est pas (Charlotte Roemer / Yves Bas)
- Outre les nombreuses méthodologiques et techniques, peut-on proposer des idées d'applications ? Par exemple pour la production de synthèses cartographiques et graphiques à partir de la BD Kakila des observations de mammifères marins en Guadeloupe (Iwan) ?









# Collaboration Fest
## Groupe 1 workflow BDD

### Synthèse générale
- **Bilan des discussions à travers le ycle de vie des données :** 
    - Planification : un PGD sera créé, il faudra clairement y afficher les objectifs de : 
        - pérennisation des données brutes des acteurs de terrain partenaires (avec import/export facilités)
        - préparation de données homogénéisées et standardisées en vue de leur analyse (via projet TRAFIC) et de leur diffusion 
        - publication des données et métadonnées via le PNDB, le SINP, le GBIF puis les géocatalogues indigeo et DRIIHM
    - Création : il faudra veiller à faciliter l'import/export des données brutes
    - Traitement/analyse : il faudra mettre en place des traitements permettant le transfert d'une partie des données brutes vers le nouveau modèle de base de données (v2) proche du modèle v1 de la base au format excel
    - Conservation : soit dans une BDD PostgreSQL/PostGIS au CC-IN2P3, soit voir avec UMS Mosaic. Travail sur le modèle de données, voir pour intégrer des métadonnées dans la base
    - Partage : 
        - prévoir des sorties de type Darwin Core Archive avec tables "event_core", "occurrence" et "measurement" et métadonnées en EML. 
        - affiner le workfow de publication : on partirait vers BDD -> PNDB (EML) -> SINP -> GBIF et aussi BDD -> géocatalogue OHM LC Geonetwork indigeo (ISO19115/19139) -> géocatalogue DRIIHM
    - Réutilisation :
        - choix de thésaurus/ontologies
            - taxref pour les espèces
            - à trouver pour les termes géographiques
            - et éventuellement les identifiants (ORCID pour les personnes ?)
- **Exemples inspirant :** OBIS, projet EnetWild http://www.gbif.fr/sites/default/files/documents/sp.efsa_.2020.en-1841.pdf et futur tableau de bord pour la surveillance de la biodiversité terrestre
- **Points de vigilance** qui complexifient le processus de partage/diffusion des données/métadonnées : le multi-langue, l'évolution des standards et des thésaurus

### CR atelier groupe 1 - 20/10 matin
- Emilie-Sarah-Guillaume-Claudia-Yvan-Amélie-Iwan-JeanLuc-Lorraine-Mariya
- tour de table
- **Présentation du sujet --> questions --> quelques clarifications et informations/recommandations :** 
    - Objectif de transférer la BDD sous Excel dans PostgreSQL/PostGIS avec diffusion à travers le catalogue du PNDB, le GBIF d'une part (avec EML) et le géocatalogue de l'OHM Littoral-Caraïbe d'autre part (avec ISO19115 and co)
    - La question du stockage : à clarifier avec Yvan si le PNDB fait le stockage ou non !
    - Recommandation par Guillaume de verser les données/métadonnées dans le SINP (contacter l'antenne régionale) sachant que le SINP (cf. portail OpenObs) utilise son propre standard mais s'oriente vers l'utilisation de Darwin core (DwC). Une passerelle existe entre SINP et GBIF. Le SINP gère toutes les données d'occurrences de la France.
    - Recommendation par Guillaume de contacter l'UMS Mosaic (techno No SQL, passerelle vers SINP automatique) et de regarder OBIS comme exemple. Vigi-nature l'utilise aussi.
    - Jean-Luc peut faire l'interface avec les acteurs locaux.
- **Présentation de la base de données BDD Kakila v1 par Lorraine**
    - Discussion autour des champs "niveau d'expertise" et "preuve visuelle" - gérer l'évolution du niveau d'expertise soit au niveau de l'observation directement soit dans une table d'historique à part 
    - "Nom/prénom" des observateurs : faire déclaration RGPD ou sinon anonymiser (voir avec cellule DPD et avis des observateurs)
    - Géolocalisation soit point X/Y (avec incertitude), soit polygone soit toponyme (et lier un locationID au niveau Dwc pour ces 2 derniers). Discussion sur la "distance (en m) au bateau". 
    - Voir pour intégrer l'instrument de mesure de géolocalisation dans observation ou au niveau des métadonnées si toujours le même type (GPS). 
    - Idem pour l'instrument d'observation : jumelles, oeil nu, autre ?
    - voir pour mieux coller avec l'idée qu'une sortie peut contenir 1 ou plusieurs observateurs

### CR atelier groupe 1 - 20/10 aprem
- Emilie-Sarah-Guillaume-Claudia-Yvan-(Iwan début)-JeanLuc-Lorraine-Mariya
- **Poursuite des discussions**
    - Iwan / Jean-luc : inquiétude de devoir tout changer la BDD alors qu'un énorme travail de saisie a été réalisé et tous les acteurs étaient d'accord. En réponse, pas d'inquiétude ! la BDD gardera une structure très similaire (petits ajustements à la marge éventuellement), ce sont les sorties qui vont être adaptées DwC et EML pour facilité l'interopérabilité et la réutilisation.
    - Questions posées à Yvan --> ses réponses
        - stockage dans PNDB ? oui si petit fichier excel par exemple, mais le PNDB n'a pas vocation à stocker les données. Partir sur une version exportée de la base par an pour publication dans PNDB (voir pour métadonées de requêtes ?)
        - Le SIB (système d'info de biodiversité) va fédérer 13 SI existants dont le SINP. Lien SIB : https://democracyos.consultation.etalab.gouv.fr/si-biodiversite
        - Partir sur un workflow BDD -> PNDB -> SINP -> GBIF
        - Attention le DwC va sans doute évoluer ! 
        - L'EML peut être aussi utilisé pour les données en plus des métadonnées, notamment dans le cas où une donnée se répète.
    - Sophie précise : le Darwin Core est un standard d'échange de données, pas de gestion (il n'est pas du tout obligatoire de transformer sa base en DwC, seule la version d'export vers des infrastructures telles que PNDB ou GBIF doit l'être).
- **Schéma proposé par Guillaume "Le standard Darwin core appliqué au suivi des mammifères marins d’AGOA (BDD Kakila)"** (merci !!) : https://data-access.cesgo.org/index.php/apps/onlyoffice/s/1MKUDQZzVdTkCPx?fileId=316684624
    - La BDD Kakila peut être quasi intégralement décrite à l'aide de DwC via les classes "Event Core", "Occurrence" et "Mesurement of fact" (comme sur le modèle utilisé par projet EnetWild).
    - Notion de parent-enfant possible pour lier différentes occurences (cas des juvéniles) et différentes mesures.
    - Dissocier la façon de stocker (BDD facilitant la saisie des données, bien structurée, potentiellement ces 3 tables + 1 table observateur + 1 table des identifiants des secteurs) de la façon de partager (DwC + EML). Sarah travaille justement sur la conversion de ces 3 tables via appli Shiny pour le tableau de bord sur la surveillance de la biodiversité terrestre.
    - Relation 1:N entre les blocs "Event core", "Occurrence" et "Measurement or Fact", relation 1:1 au sein des blocs (rem : pour observateur ça peut être une liste d'observateurs).
- **Identifier des thésaurus ou ontologies**
    - TAXREF validé par tous pour les espèces. Jean-Luc souligne l'existence d'un référentiel pour les mammifères marins : https://marinemammalscience.org/species-information/list-marine-mammal-species-subspecies/ : pour les environ 30 espèces, après vérification, on pourra faire sans problème le lien entre ce référentiel et la CD-Ref de Taxref.
    - quid du biome/écorégion, existe-t-il un thésaurus/ontologie ? on ne sait pas -> QUESTION A POSER A TOUT LE MONDE ???
    - associer le numéro de version à TAXREF dans les métadonnées
    - quid utilisation du thésaurus ANAEE ? plutôt pour les mots-clés éventuellement
    - utiliser si possible des thésaurus pour les termes géographiques et les identifiants.
- **Définitions métadonnées vs données :** il peut y avoir plusieurs niveaux de description de métadonnées de haut niveau (méta-programme, projet) jusqu'à la description du jeu de données/table. En deça, c'est de la donnée.
- **Points de vigilance** qui complexifient le processus de partage/diffusion des données/métadonnées : le multi-langue, l'évolution des standards et des thésaurus
- **Darwin Core Archive :** 
    - peut être en sortie de la BDD Kakila pour faciliter le transfert vers PNDB et cie
    - GBIF utilise un set d'EML minimal : 
        - Les pré-requis GBIF pour les jeux de données d'occurrences : https://www.gbif.org/data-quality-requirements-occurrences 
        - et pour les jeux de données de type Event : https://www.gbif.org/data-quality-requirements-sampling-events
        - un exemple d'archive Darwin Core : http://ipt.gbif.fr/archive.do?r=inra_ang_scorff&v=1.1
    - l'OFB travaille dessus actuellement en lien avec le tableau de bord (tronc commun avec MetaShARK). Guillaume illustre les idées de champs utilisé dans le cadre du tableau de bord : https://data-access.cesgo.org/index.php/apps/onlyoffice/s/1MKUDQZzVdTkCPx?fileId=316684622
- **Fiche métadonnées générée via R MetaShARK pour la BDD Kakila au format excel :** 
    - Emilie propose de stocker en base une partie des métadonnées qui décrit la BDD et les tables pour faciliter ensuite l'export en EML -> stratégie déjà utlisée par Guillaume (pour décrire les différents niveaux de métadonnées) et par Claudia (pour faciliter la création de fiches de métadonnées dans geonetwork, basé au départ sur packages R geometa/geonapi/geosapi)
    - présentation rapide de R geoflow avec son template de saisie basé sur Dublin Core permettant de générer des fiches ISO19115/19139. Emilie réfléchit à l'utilisation de ce format pivot qui pourrait alimenter d'une part l'EML et d'autre part l'ISO. Attention à la perte de métadonnées, notamment celles décrivant la démarche scientifique/stratégie d'échantillonnage pour les données opportunistes notamment ! Guillaume préconise plutôt BDD -> PNDB (EML) -> geonetwork (ISO).
    - Guillaume présente un exemple de métadonnées complètes dans https://professionnels.ofb.fr/fr/node/1089 ici : http://carmen.carmencarto.fr/IHM/metadata/ONCFS/Publication/MTD_auto_Carmen/Ongules_sauvages/ficheMTD_Ongules_de_montagne_2016_BOQ.pdf
- **Quid gestion des données d'absence d'espèces pendant les sorties :** il faut l'expliquer dans les métadonnées que seules les présences sont renseignées (ce qui sous-entend les absences des autres espèces) et/ou prévoir en sortie des sorties sans occurence pour les espèces non vues/identifiées. A discuter avec Jean-Luc et Iwan.
- **Citation de la BDD Kakila** en cas de travaux la réutilisant : ... merci de compléter Jean-Luc

### CR atelier groupe 1 - 21/10 matin
- **Clarification des objectifs** 
    - pérennisation des données brutes des acteurs de terrain partenaires (avec import/export facilités)
    - préparation de données homogénéisées et standardisées en vue de leur analyse (via projet TRAFIC) et de leur diffusion 
    - publication des données et métadonnées via le PNDB, le SINP, le GBIF puis les géocatalogues indigeo et DRIIHM
    - ***Travail à faire** : Lorraine enverra à Sarah les exemples de fichiers de données brutes.*
- **Travail sur le modèle physique de données proposé par Emilie** 
    - le modèle a été expliqué puis légrèrement modifié : ajout table "taxon" -> veiller aux correspondances avec le code-espèce utilisé par les acteurs de terrain
    - ***Travail à faire :*** 
        - *Emilie et Lorraine vont transformer le fichier excel v1 en v2 avec traitements des données associés*
        - *Lorraine va compléter le glossaire des noms de taxons avec les éventuels taxons manquants et leur code équivalent dans les fichiers de données brutes (code_espece)* 
        - *Lorraine (avec Iwan) va génerer une couche SIG des noms de secteurs géographiques. Cette couche sera ensuite ttransformée en table dans la BDD**

#### Références
Référence pour Kakila
1 - Lorraine Coché : Inventaire et structuration des données d'observation des mammifères marins aux abords de la Guadeloupe, Stage de Master 2, Master Écosystèmes marins tropicaux à l'université des Antilles. Soutenu le 29 juin 2020

2 - Lorraine Coché, Laurent Bouveret, Benedicte Madon, Romain David, Yvan Le Bras, Maxime Sèbe, Nadège Gandhillon, Claire Frericks, Pascal Jean Lopez, Eric Foulquier, Jean-Luc Jung & Iwan Le Berre. Kakila database : A FAIR community approved database of cetacean presence in the waters of the Guadeloupe archipelago. Datapaper in redaction

3 - La liste des contributeurs (associations et structures)

![](https://i.imgur.com/txPYyLS.png)


4 - OHM Litorral Caraibe, LabEx DRIIHM, programme “Investissements d’avenir”  portant la référence ANR-11-LABX-0010”


















4 - OHM Litorral Caraibe, LabEx DRIIHM, programme “Investissements d’avenir”  portant la référence ANR-11-LABX-0010”
--

### CR atelier groupe 1 - 21/10 matin
- **Atelier EML** 
    - Refs EML : les ressources les plus user friendly sont https://eml.ecoinformatics.org/ et la doc interactive du schéma EML https://eml.ecoinformatics.org/schema/ et sinon dans MetaShARK https://metashark.test.pndb.fr/ partie "EML Documentation" où on peut chercher des termes EML par mots-clés dans une arborescence représentant tous les modules EML.
    - Quels sont les termes de l'EML qui sont nécessaires pour un draft de data paper ?
        - Exemple de la BDD de Lorraine (généré par R emldown via R MetaShARK) : manque les infos sur les taxons -> pb lié à EMLAL apparemment
        - R emldown = bonne base mais à compléter pour les infos de provenance (méthode, protocole, historique de production des données) -> YLB en cours de réflexion mapping avec thésaurus EnvThes (object of interest, method, research focus) pour structurer le champ Method (avec EML step)
        - Pour Guillaume, il est important de renseigner la stratégie d'échantillonnage, la qualité de la méthode de terrain et la qualité de l'analyse) pour qualifier la qualité du résultat
        - attention au risque de trop (tout) standardiser !
    - Tentative de mapping EML à partir du tableau de bord surveillance biodiversité terrestre (Guillaume)
        - exemple : "titre projet" devient project tile en EML
        - exemple 2 : date début projet = study area Description / coverage / temporal coverage / RangeofDates / beginDate
        - il faut chercher via la doc de Metashark puis récupérer le XSD path (attention, pas toujours bon dans la doc !)
- **Travail mapping Darwin Core de Sarah** https://docs.google.com/spreadsheets/d/1syHpy2_TYVL_kMFaKukgI2DD7GW_r5I7WffcvnQ2EFw/edit#gid=52385069
    - discussions et validation du mapping
Fin de l'atelier, super boulot, merci à tous !!!!


Voir lien d'emboitement entre project / dataset-software-literature-protocol (top level resource)

"Related Project", lien parent / enfant et voir si possibilité de mettre plusieurs projets enfants d'un projet. ResearchProject pour parent/ RelatedProject pour enfant

ResourceModule/DistributionType pour mentionner un URL pour un projet cousin (sans lien ) ... Peut-être utiliser "ReferenceGroup"



## Groupe 2 - Package R / conversion de scripts R en packages

- Loubna, Alain, Simon, Sébastien, Nicolas, Philippe et Sab
- Conversion d'un ensemble de scripts/fonctions R en un package R via cours prvié Sébastien
- Dépôt GitHub privé de Loubna / Vigie-NAture
- Dépôt GitHub privé d'Alain (reconstitution de réseaux trophiques piscicole)
- Nous suivons les étapes de ce post (écrit par Sébastien après le hackathon de l'année dernière) : [https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/](https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/)

Pour le bon emploi des emoji dans les commits (non officiel) :
https://gist.github.com/parmentf/035de27d6ed1dce0b36a

- Résultat de l'atelier R Package (structure idéale d'un package, sans les tests malheureusement) : 
    - [Package](https://github.com/loubnaelmadouri/hackathon)
    - [Site Web](https://loubnaelmadouri.github.io/hackathon/)
    - [Zenodo](https://zenodo.org/record/4115401)

- Loubna a tout fait :panda_face:, :tada:, :boom:, :see_no_evil:

## Groupe 3 Shiny
Charlotte, Raphaelle, Morgane

Un peu dans tous les sens car 3 use cases différents

Golémisation réussie, notamment avec Charlotte et Raphaelle. Morgane avait déjà app Shiny modularisée et complexe

Packaging d'application R également avec orientation Shiny. 

Obtention de Dockerfiles via {golem}. Pas le temps pour setup un serveur ET montrer comment employer Docker pédagogiquement :/ 

Correction et aperçus de plusieurs bugs. 

Méthodes de debuggage: utiliser l'inspecteur de code pour localiser les éléments fautifs. 

https://training.galaxyproject.org/training-material/topics/dev/tutorials/tool-integration/slides.html#1

Tests d'application Shiny:

- Package {shinytest}: très rigide
- Package {rselenium}: comme Galaxy emploie Selenium pour tester son code, employer R Selenium pourrait permettre d'écrire des tests pour Shiny.


## Groupe 4 FAIR implementation Profile
- Amélie Envri-FAIR / In-sylva - collègue de Mariya qui fait de la curation sur thesaurus Anaee / lien D2Kab
- Françoise Le Moal
- Philippe Clastre
### FIP OSURIS
    - BAckground dossier partagé ici https://data-access.cesgo.org/index.php/s/P79IqHpT8pfRdFv avec deux fichiers word avec les informations pratiques pour mener une interview pour remplir le questionnaire permettant de créer le fameux FAIR Implementation Profile, ou FIP ;) et un fichier .pdf qiu est le résultat du premier FIP que j'ai créé pour le GBIF. Bon, pas forcément parfait, mais je trouve intéressant de tenter de remplir ce genre de questionnaire par communauté et SI lié. Dans les fichiers word ils expliquent comment faire le travail en utilisant https://fip-wizard.ds-wizard.org/ après s'être créé un compte pour répondre au questionnaire, et même l'installation de l'outil nanobench pour créer ce qu'ils appellent des nanopublications, une nanopublication décrivant une nouvelle ressource pouvant être sélectionnée dans le questionnaire (pour les réponses au questionnaire pas dans la liste des propositions ni dans wikidata). Là c'est un peu technique, mais une façon de faire serait ""juste"" de prendre le document pdf en version word (je dois l'avoir qqpart) et le remplir pour chaque communauté / SI. (Françoise Le Moal ?)
    - Test sur OSURIS, pas que biodiv !
        - https://www.osuris.fr/geonetwork/srv/fre/catalog.search;jsessionid=046CE2A5CE52CD79A2616D0F0150CC76#/home
        - https://accueil.osuris.fr/

- commentaires
    - General
        - Searching on wikidata filed, there is no standardisation, for example 10 different entities for XML...(XML, xml, Extended Markup Language,...)
    - F1 Q2 pas d'identifiants sur données, que sur métadonnées
    - F3 Q4 lien données métadonnées par la métadonnée. Comment le spécifier ? On met metadata pour le moment
    - (Ajouter CSW pour protocole accès MTD)
    - A2 Q5 metadata longevity plan -> créer un document pour OSURIS
        - unable to type hint (5.3.a)
    - I1 Q2 what the difference between dataset and metadata representation language ?? 
    - R1.1 licence from geonetwork is for only metadata document AND/OR datasets ?
        - PRovenance peut être vu comme la date de création, mais aussi les notions d'agents (pouvant être logiciel) ayant agit sur la création de données! Quelle étape la donnée a parcouru pour arriver dans la bdd?
        - voir SSN https://www.w3.org/TR/vocab-ssn/#SSNSYSTEMinCondition et SOSA pour les capteurs. Ressources pour provenance : https://mssanz.org.au/modsim2017/C2/cox.pdf

### FIP ANAEE
http://w3.avignon.inra.fr/geonetwork_anaee/srv/fre/catalog.search#/home

Description de structures expérimentales, avec points de contact.


Voir téléchargement depuis GeoNetwork en rdf et lien endpoint

Quelle est la manière de décrire provenance fine (via PROV-O par exemple) en OGC compatible ? Dans ISO 19115  ?

-> Answered: 52/117 because there is an error ? 117 = all the possible fields ?


## Groupe 6 Mapping IN-SYLVA / EML

Descritpion IN-SYLVA https://www6.inrae.fr/in-sylva-france/Services/In-Situ


resourcedatatype / creation-publication-revision -> Si revisions, alors équivalence EML https://eml.ecoinformatics.org/schema/eml-dataset_xsd.html#MaintenanceType_MaintenanceType_changeHistory_changeDate

Combinaison DatasetType EML + keywordSet/Keyword ET/OU ResourceGroup/ResourceType http://w3.avignon.inra.fr/gn_plateau_ressources/INSYLVA/resource.IN-SYLVA_type.js

Proposer des listes de keywords contraints genre INSPIRE (topic categories https://inspire.ec.europa.eu/metadata-codelist/TopicCategory IN-SYLVA plutôt dans environnement), IN-SYLVA dans MetaShARK


Faire amalgame ResrouceType IN-Sylva avec ResearchProject de EML ? -> https://eml.ecoinformatics.org/schema/eml-project_xsd.html#ResearchProjectType_designDescription / mais cela voudrait dire que on définie experimental site ou analytic platform comme un projet pour lineage / provenance

PId de publication de référence : https://eml.ecoinformatics.org/schema/eml-dataset_xsd.html#DatasetType_referencePublication + ResourceGroup avec PhysicalDistributionType/online/url / Voir si URI, module annotation avec ressources sémantique

Ambiguités potentielles, toujours bon d'échanger dans le détail ;)

ForestType -> controlList à partir de 14 types de cet article https://link.springer.com/article/10.1007/s13595-017-0674-6 + 2-3 types tropicaux étudiés dans le cadre du réseau TMFO

Types de groupes de sols de référence https://inspire.ec.europa.eu/codelist/WRBReferenceSoilGroupValue/ peut-être réutilisable via le module semantics

Type de forêt, caractéristique d'humus, ... chacun dans un keywordSet

Type d'humus https://www.researchgate.net/publication/332080061_TerrHum_an_iOS_App_for_classifying_terrestrial_humipedons_and_some_considerations_about_soil_classification (p4) (Mull/Amphi...)

Les réseaux expérimentaux = liste contrôlé de réseaux rassemblant des sites expérimentaux (p42 spec), avec potentiellement >100 sites par réseau

Voir vocbench3 http://w3.avignon.inra.fr/vocbench3/ et demande de compte pour parcourir les listes contrôlées

23 termes sur 117 ;)

## Groupe 5 metacat-solr-geoserver

Julien, Arnaud

Ils nous avaient promis le Graal !

Présentation catalogue metacat, lien avec solr et geoserver lié à metacat
- intérêt de connecter geoserver à solr ou la bdd directement après avoir regardé la structure de la bdd metacat
    - ça parait compliqué de connecter un geoserver dessus et il y aurait obligation de passer par une vue, complexe à créer
- donc test connection geoserver sur le solr directement
    - pas mal de config à faire, peur de tout casser
    - puis install partie dédié pour pas tout casser
    - installation Docker sur serveur test sur openstack avec Geoserver et un solr, le Grall était de pouvoir relier les 2, mais pas réussi..... Pourtant install neuve...
- aujourd'hui voir pourquoi la connection ne fonctionne pas !


"on essaye de comprendre quel schema solr est compris par geoserver"


## Vigie-Nature Ecole et data paper
Data Paper, définition aléatoire en fonctione des gens.
Sur VNE, les données sont bien connues, et du coup, idée de les représenter sous forme de data paper serait cool.
-> peut-être via emldown / vision PNDB / MetaShARK ?

Export des bdd pour renseignement EML et emldown pour création Data Paper avec pourquoi pas possibilité de création / insertion de choses interactives
- le faire à temps de pas régulier

Pouvoir créer des data paper et y insérer de la sortie de Shiny par exmeple pour avoir des pages propres data paper interactives.

Partir des 4 protocoles Galaxy-Bricks, MetaShARK avec emldown et customisation à la main et/ou travail de la part de VNE sur package emldown


## Coline Galaxy tools métriques de biodiv / glm
Test workflow PAMPA calcul métriques de biodiversité sur nouvelles données "pêche".



Aide de Simon sur training-material dans e futur


## Interactive tools
proposer un interactive tools Shiny par exmeple dans Galaxy / Galaxy-Bricks pour avoir une prévisualisation des résultats d'un workflow qui automatiquement sélectionnerait Xpourcent des données afin que l'utilisateur puisse faire un choix sur quel workflow choisir.

# TO-DO
- session Docker GIS (Philippe Clastre/Mathias/Nicolas Casajus )
- Sémantique / sémantisation via OBOE / désémantisation pour publication dans entrepôt genre Dataverse (Philippe Clastre ANAee, Amélie ENVRI-FAIR)
- intégration données hétérogènes (Raphaelle)


# Ressources
- Info Docker sous Windows : https://korben.info/installer-docker-windows-home.html
- Article de blog rédigé l'année dernière suite à eocinfoFAIR 2019 "Transformer plusieurs scripts éparpillés en beau package R" https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/
- Méthode "Rmd first" : Rmd first, ça veut dire qu'on commence le développement dans un fichier Rmarkdown (texte + script R classique).
  + Ce qu'on a fait l'an dernier : https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/
  + Les slides d'une prez ici: https://github.com/statnmap/prez/blob/master/2019-07_useR_Toulouse.pdf
  + La version longue dans un article de blog, c'est ici: https://rtask.thinkr.fr/fr/quand-le-developpement-commence-par-la-documentation/
- Provenance : voir SSN https://www.w3.org/TR/vocab-ssn/#SSNSYSTEMinCondition et SOSA pour les capteurs. Ressources pour provenance : https://mssanz.org.au/modsim2017/C2/cox.pdf
- pour le CSS :
https://www.w3schools.com/cssref/pr_pos_right.asp
https://fr.learnlayout.com/position.html

# Chanson
## Golemization -> sur air de Califonication ( Red Hot Chili Pepper)
## FIP -> FIP la la la la la
## FIP related
J'ai cliqué sur les mots bleu, souligné au crayon bleu
Ouvrir un onglet me semble ridicule, je clique droit et puis je recule
## FIP related
Le Chocard existe encore
## FIP related
En rouge et noir
## Technically related
C'est la room de trop,
moi la room bigbluebutton j'en ai fait peut-être un peu trop

## Born to be a FIP

## FAIR de la restitution en chantant

scarborough F.A.I.R 

## Solr pleure
geoserver

## Y'a de la room (bbb) dans l'air

##Et si tu n'existait pas (URI / Vocbench)

## Ma Phylosophie
Je n'ai qu'une philosophie
Être acceptée comme je suis
Malgré tout ce qu'on me dit
Je reste le poing levé

les emoji c'est la vie